{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# affine function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x :[[10. 20.]]\n",
      "init :[]\n",
      "W: [[ 0.8066164]\n",
      " [-1.0093138]], B: [0.]\n",
      "y_tf :[[-12.120111]]\n",
      "y_man :[[-12.120111]]\n",
      "===== 0 =====\n",
      "x :[[10. 20.]]\n",
      "init :[]\n",
      "W: [[-1.3778957]\n",
      " [ 1.2569524]], B: [0.]\n",
      "y_tf :[[11.36009]]\n",
      "y_man :[[11.36009]]\n",
      "===== 1 =====\n",
      "x :[[10. 20.]]\n",
      "init :[]\n",
      "W: [[1.3344394 ]\n",
      " [0.81205165]], B: [0.]\n",
      "y_tf :[[29.585426]]\n",
      "y_man :[[29.585426]]\n",
      "===== 2 =====\n"
     ]
    }
   ],
   "source": [
    "for iii in range(3):\n",
    "    \n",
    "    x = tf.constant([[10.,20.]]) # input -> matrix\n",
    "    print(f'x :{x}')\n",
    "    dense=Dense(units=1, activation='linear') # affine function, linear 디폴트, linear일때 activation없이 그대로 나옴\n",
    "    print(f'init :{dense.get_weights()}')\n",
    "    y_tf = dense(x) # forward propagation + params initialization , 초기화 여기서\n",
    "    \n",
    "\n",
    "    W,B = dense.get_weights()\n",
    "    print(f'W: {W}, B: {B}') # 초기 W는 랜덤\n",
    "    \n",
    "    print(f'y_tf :{y_tf}')\n",
    "    y_man = tf.linalg.matmul(x,W)+B\n",
    "    print(f'y_man :{y_man}')\n",
    "    \n",
    "    \n",
    "    print(f'===== {iii} =====')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameter initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.initializers import Constant # 원하는값으로 초기값 셋팅할수있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,b = tf.constant(10.), tf.constant(20.)\n",
    "w_init, b_init = Constant(w), Constant(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.initializers.initializers_v2.Constant object at 0x7f34e83ce410> <keras.initializers.initializers_v2.Constant object at 0x7f34e83ce390>\n"
     ]
    }
   ],
   "source": [
    "print(w_init,b_init) # 초기화시켜주는 object, 값이 아님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[10.]], shape=(1, 1), dtype=float32)\n",
      "[[10.]] [20.]\n",
      "tf.Tensor([[120.]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# affine function\n",
    "x = tf.constant([[10.]])\n",
    "dense = Dense(units=1,\n",
    "             activation='linear',\n",
    "             kernel_initializer=w_init,\n",
    "             bias_initializer=b_init)\n",
    "y_tf=dense(x)\n",
    "\n",
    "W,B=dense.get_weights()\n",
    "\n",
    "print(x) # x가 row vector, T의 주체가됨.(원래 vector라서 세로) 이유는 보기편해서 그렇게 쓰기시작함..\n",
    "print(W,B) # 그래서 W는 벡터 그대로 세로로 구성되어있음\n",
    "# 암튼 넣어준 셋팅이 잘 들어가있는걸 확인할 수 있음\n",
    "\n",
    "print(y_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[10. 20.]], shape=(1, 2), dtype=float32)\n",
      "[[10.]\n",
      " [10.]] [20.]\n",
      "tf.Tensor([[320.]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# affine function\n",
    "x = tf.constant([[10.,20.]])\n",
    "dense = Dense(units=1,\n",
    "             activation='linear',\n",
    "             kernel_initializer=w_init,\n",
    "             bias_initializer=b_init)\n",
    "y_tf=dense(x)\n",
    "\n",
    "W,B=dense.get_weights()\n",
    "\n",
    "print(x) \n",
    "print(W,B) \n",
    "print(y_tf) # 스칼라"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with n features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.3972139 6.8853416 5.9009814 7.8735995 7.2339525 6.7133274 6.521467\n",
      "  7.089095  4.6512675 9.065267 ]], shape=(1, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x=tf.random.uniform(shape=(1,10), minval=0, maxval=10)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.3972139 6.8853416 5.9009814 7.8735995 7.2339525 6.7133274 6.521467\n",
      "  7.089095  4.6512675 9.065267 ]], shape=(1, 10), dtype=float32)\n",
      "[[ 0.5331724 ]\n",
      " [ 0.33689493]\n",
      " [ 0.62697357]\n",
      " [ 0.7281448 ]\n",
      " [-0.294192  ]\n",
      " [ 0.07094663]\n",
      " [ 0.32891804]\n",
      " [ 0.5812668 ]\n",
      " [-0.65473163]\n",
      " [ 0.30671114]] [0.]\n",
      "tf.Tensor([[16.846361]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor([[16.846361]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dense= Dense(units=1)\n",
    "y_tf=dense(x) # 여기서 w,b초기화됨\n",
    "W,B = dense.get_weights()\n",
    "y_man=tf.linalg.matmul(x,W)+B\n",
    "    \n",
    "print(x) \n",
    "print(W,B) \n",
    "print(y_tf) \n",
    "print(y_man) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.math import exp, maximum\n",
    "from tensorflow.keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 0 =====\n",
      "x: [[-0.1335118 -0.675061   1.388644   1.4651606  0.9662373]]\n",
      "sigmoid\n",
      "[[0.46667156 0.33736452 0.80037564 0.8123207  0.7243689 ]]\n",
      "[[0.46667156 0.33736452 0.8003757  0.8123207  0.7243689 ]]\n",
      "tanh\n",
      "[[-0.13272409 -0.58829916  0.8828722   0.8986503   0.7470462 ]]\n",
      "[[-0.13272412 -0.5882992   0.88287216  0.8986502   0.74704623]]\n",
      "relu\n",
      "[[0.        0.        1.388644  1.4651606 0.9662373]]\n",
      "[[0.        0.        1.388644  1.4651606 0.9662373]]\n",
      "===== 1 =====\n",
      "x: [[-0.9960115   0.37351587 -0.89543474 -0.5528513  -1.2225705 ]]\n",
      "sigmoid\n",
      "[[0.2697263  0.5923083  0.28998956 0.3652031  0.2274844 ]]\n",
      "[[0.26972634 0.5923082  0.28998956 0.36520314 0.22748442]]\n",
      "tanh\n",
      "[[-0.75991404  0.3570632  -0.71406776 -0.50265414 -0.8404108 ]]\n",
      "[[-0.759914    0.35706314 -0.71406764 -0.50265414 -0.8404108 ]]\n",
      "relu\n",
      "[[0.         0.37351587 0.         0.         0.        ]]\n",
      "[[0.         0.37351587 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "for iii in range(2):\n",
    "    print(f'===== {iii} =====')\n",
    "    x=tf.random.normal(shape=(1,5))\n",
    "\n",
    "    sigmoid=Activation('sigmoid')\n",
    "    tanh=Activation('tanh')\n",
    "    relu=Activation('relu')\n",
    "\n",
    "    y_sigmoid_tf=sigmoid(x)\n",
    "    y_tanh_tf=tanh(x)\n",
    "    y_relu_tf=relu(x)\n",
    "\n",
    "    y_sigmoid_man= 1 / (1+exp(-x))\n",
    "    y_tanh_man= (exp(x)-exp(-x))/ (exp(x)+exp(-x))\n",
    "    y_relu_man= maximum(x,0)\n",
    "\n",
    "    print(f'x: {x.numpy()}')\n",
    "    print('sigmoid')\n",
    "    print(y_sigmoid_tf.numpy())\n",
    "    print(y_sigmoid_man.numpy())\n",
    "\n",
    "    print('tanh')\n",
    "    print(y_tanh_tf.numpy())\n",
    "    print(y_tanh_man.numpy())\n",
    "\n",
    "    print('relu')\n",
    "    print(y_relu_tf.numpy())\n",
    "    print(y_relu_man.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![그래프으](https://mblogthumb-phinf.pstatic.net/MjAyMDAyMjVfMTQ3/MDAxNTgyNjA5NDY3MTY3.228bUv_5mrol1w7X0NiFMD1UNru9zyf3yIJGcON-An0g.3Kzynlja9y_F9yTfANl937elQAK1pTGoJ_al7Om7TYsg.PNG.handuelly/image.png?type=w800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[array([[10.],\n",
      "       [10.],\n",
      "       [10.],\n",
      "       [10.],\n",
      "       [10.]], dtype=float32), array([20.], dtype=float32)]\n",
      "[array([[10.],\n",
      "       [10.],\n",
      "       [10.],\n",
      "       [10.],\n",
      "       [10.]], dtype=float32), array([20.], dtype=float32)]\n",
      "[array([[10.],\n",
      "       [10.],\n",
      "       [10.],\n",
      "       [10.],\n",
      "       [10.]], dtype=float32), array([20.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "x=tf.random.normal(shape=(1,5))\n",
    "dense_sigmoid=Dense(units=1, activation='sigmoid',\n",
    "                    kernel_initializer=w_init,\n",
    "                     bias_initializer=b_init)\n",
    "dense_tanh=Dense(units=1, activation='tanh',\n",
    "                    kernel_initializer=w_init,\n",
    "                     bias_initializer=b_init)\n",
    "dense_relu=Dense(units=1, activation='relu',\n",
    "                    kernel_initializer=w_init,\n",
    "                     bias_initializer=b_init)\n",
    "print(dense_sigmoid.get_weights())\n",
    "print(dense_tanh.get_weights())\n",
    "print(dense_relu.get_weights())\n",
    "\n",
    "y_sigmoid=dense_sigmoid(x)\n",
    "y_tanh=dense_tanh(x)\n",
    "y_relu=dense_relu(x)\n",
    "\n",
    "print(dense_sigmoid.get_weights())\n",
    "print(dense_tanh.get_weights())\n",
    "print(dense_relu.get_weights())\n",
    "\n",
    "# 스칼라 만들때까지 W,B 당연히 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "y_sigmoid :[[0.57127315]]\n",
      "y_tanh :[[0.8933138]]\n",
      "y_relu :[[0.27782315]]\n",
      "y_sigmoid :[[0.57127315]]\n",
      "a :[[0.57127315]]\n",
      "======\n",
      "y_sigmoid :[[0.6230923]]\n",
      "y_tanh :[[-0.9600379]]\n",
      "y_relu :[[0.]]\n",
      "y_sigmoid :[[0.6230923]]\n",
      "a :[[0.6230923]]\n",
      "======\n",
      "y_sigmoid :[[0.19291122]]\n",
      "y_tanh :[[-0.22478244]]\n",
      "y_relu :[[1.3350224]]\n",
      "y_sigmoid :[[0.19291122]]\n",
      "a :[[0.19291122]]\n"
     ]
    }
   ],
   "source": [
    "for ii in range(3):\n",
    "    print('======')\n",
    "    x=tf.random.normal(shape=(1,5))\n",
    "    dense_sigmoid=Dense(units=1, activation='sigmoid')\n",
    "    dense_tanh=Dense(units=1, activation='tanh')\n",
    "    dense_relu=Dense(units=1, activation='relu')\n",
    "\n",
    "    # forward propagation\n",
    "    y_sigmoid=dense_sigmoid(x)\n",
    "    y_tanh=dense_tanh(x)\n",
    "    y_relu=dense_relu(x)\n",
    "\n",
    "    print(f'y_sigmoid :{y_sigmoid.numpy()}') # W,B타고나온 스칼라값에 태우는것이기 때문에 스칼라임\n",
    "    print(f'y_tanh :{y_tanh.numpy()}')\n",
    "    print(f'y_relu :{y_relu.numpy()}')\n",
    "    # 크기는 제각각이긴 하네\n",
    "    \n",
    "    w,b = dense_sigmoid.get_weights()\n",
    "    z= tf.linalg.matmul(x,w)+b\n",
    "    a = 1/(1+exp(-z))\n",
    "    \n",
    "    print(f'y_sigmoid :{y_sigmoid.numpy()}')\n",
    "    print(f'a :{a.numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 10)\n",
      "[[ 0.06125021]\n",
      " [-0.1204198 ]\n",
      " [-0.18354303]\n",
      " [ 0.47030133]\n",
      " [-0.4995182 ]\n",
      " [-0.15719211]\n",
      " [ 0.34705073]\n",
      " [ 0.03163803]\n",
      " [ 0.09772104]\n",
      " [-0.0639376 ]] [0.]\n",
      "(8000, 10) (10, 1) (1,)\n"
     ]
    }
   ],
   "source": [
    "# 미니배치 사이즈는 W,B에 영향을 미치지 않음\n",
    "N, n_features = 8000,10 \n",
    "x = tf.random.normal(shape=(N, n_features))\n",
    "print(x.shape) # row vector\n",
    "\n",
    "dense = Dense(units=1, activation='relu')\n",
    "y=dense(x)\n",
    "\n",
    "W,B = dense.get_weights()\n",
    "print(W,B) ##### <- 사실상 이거 형태 생긴거 보려고 지금까지 한거임..\n",
    "print(x.shape, W.shape, B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_tf: \n",
      " [[0.35593018]\n",
      " [0.8355185 ]\n",
      " [0.8939175 ]\n",
      " [0.53791136]\n",
      " [0.888183  ]\n",
      " [0.05093066]\n",
      " [0.8572016 ]\n",
      " [0.9290523 ]]\n",
      "y_man: \n",
      "[[0.35593018]\n",
      " [0.8355185 ]\n",
      " [0.89391756]\n",
      " [0.5379114 ]\n",
      " [0.88818294]\n",
      " [0.05093066]\n",
      " [0.8572016 ]\n",
      " [0.9290523 ]]\n"
     ]
    }
   ],
   "source": [
    "N, n_features = 8,10 \n",
    "x = tf.random.normal(shape=(N, n_features))\n",
    "dense = Dense(units=1, activation='sigmoid')\n",
    "y_tf=dense(x)\n",
    "\n",
    "W, B =dense.get_weights()\n",
    "\n",
    "y_man = tf.linalg.matmul(x,W)+B\n",
    "y_man = 1/ (1+exp(-y_man))\n",
    "\n",
    "print(f'y_tf: \\n {y_tf.numpy()}')\n",
    "print(f'y_man: \\n{y_man.numpy()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "딥러닝 architecture\n",
    "corelation filter들을 묶어서 filter bank를 만들고\n",
    "그 filter bank의 Cascaded 구조가 딥러닝 구조임\n",
    "\n",
    "블랙박스가 아니다\n",
    "MFCC가 여기서 나오네.. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "어쨌든 각 레이어마다 다른 주파수의 영역을 판단한다는걸 말하고자했던거 같음\n",
    "'''\n",
    "\"Cascaded Deep Learning\"은 다단계로 연결된 심층 학습 모델을 의미합니다. 이는 여러 개의 신경망이 연속적으로 학습되어 더 복잡한 작업을 수행하는 방식을 나타냅니다.\n",
    "\n",
    "일반적으로, 첫 번째 신경망은 초기 입력 데이터를 받아 중간 수준의 특징을 추출합니다. 이 특징들은 두 번째 신경망에 전달되어 더 높은 수준의 특징을 추출합니다. 이런 식으로 여러 단계를 거쳐 더 복잡한 정보를 추출하게 됩니다.\n",
    "\n",
    "예를 들어, 얼굴 인식 시스템에서는 첫 번째 신경망이 저수준의 특징 (예: 선, 에지)을 추출하고, 두 번째 신경망은 이러한 특징을 결합하여 눈, 코, 입과 같은 고수준의 특징을 추출할 수 있습니다.\n",
    "\n",
    "Cascaded Deep Learning의 장점은 다양한 수준의 특징을 추출하고 이를 활용하여 더 정확한 예측이나 분류를 수행할 수 있다는 점입니다. 또한 각 단계에서 학습된 모델을 재사용하여 효율적으로 학습할 수 있습니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "뉴런마다 인풋값이 전부다 연결되어있는것\n",
    "네트워크\n",
    "node(뉴런)-edge(커넥션)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "선형대수특 값을 따로 가지고다니기 귀찮아서 한꺼번에 vector, matrix 형태로 가지고다님\n",
    "셋팅한 1,2,3...n개의 뉴런의 연산을 그대로 해줄 수 있는 구조로 만든거임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x^TW+b^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias로 row vector로 만드는데, 나중에 broadcasting같은 기능 사용할때 더 편함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "그리고 그냥 뉴런 하나씩 연산하고 activation scalar형태로 태우는거니까\n",
    "뉴런갯수만큼 vector가 layer의 output으로 나오겠지\n",
    "뉴련갯수 왜 헷갈리게 l로 표기하는걸까.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$R^{1 \\times l}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row vector(xT)를 넣어서 row vertor(결국 각각의 activation value들)가 나온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "저번시간이랑 다른게 뭔지 잘 모르겠네"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "그 다음 레이어부터는 xT가 아니라 output자체가 넘어옴. l길이를 가진 row vector\n",
    "새로운 xT로 봐줘도 되겠다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$W \\in {R^{l_{i-1} \\times l_i}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "결국 이전 결과 i-1번째의 뉴런길이 l_{i-1}와 현재 뉴런길이가 W의 크기를 만듦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# minibatches\n",
    "이제 영민이에서.. 민수, 민지가 생김"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$R^{1\\times l}$$ 을 쓴게..\n",
    "&rightarrow;\n",
    "$$R^{N\\times l}$$ 할려고였군.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix가 있을때 가로(row)는 각각 사람(N)에 대한거고 (Batch-wise)\n",
    "열은 셋팅한 과목수 or 모든 과목의 정보를 담고있는 뉴런수임 (Neuron-wise)\n",
    "\n",
    "하나의 mini batch는 하나의반임\n",
    "\n",
    "구니까 원래 구조를 떠올리려면 한사람만 떠올리면 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Laysers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (1, 10)\n",
      "W: (10, 3)\n",
      "B: (3,)\n",
      "Y: (1, 3)\n",
      "\n",
      "[[-0.41952312  0.4716655  -0.5002242 ]\n",
      " [ 0.5600183   0.5002588   0.10658395]\n",
      " [ 0.4985876  -0.27985284  0.27077603]\n",
      " [-0.10455358 -0.592419   -0.01186359]\n",
      " [-0.01741588  0.37600327  0.3161683 ]\n",
      " [-0.23857275 -0.56369627  0.39198697]\n",
      " [ 0.45858657  0.3405639  -0.21674198]\n",
      " [-0.03214979  0.5238031  -0.6376017 ]\n",
      " [-0.05144036  0.50637543  0.453781  ]\n",
      " [ 0.43707895 -0.07747614 -0.16472238]]\n",
      "\n",
      "tf.Tensor([[0.6508973 0.4733562 0.6782346]], shape=(1, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "N, n_feature =1, 10\n",
    "X= tf.random.normal(shape=(N,n_feature))\n",
    "\n",
    "n_neuron=3\n",
    "dense=Dense(units=n_neuron, activation='sigmoid')\n",
    "Y=dense(X)\n",
    "\n",
    "W,B = dense.get_weights()\n",
    "\n",
    "print('X:',X.shape)\n",
    "print('W:',W.shape)\n",
    "print('B:',B.shape)\n",
    "print('Y:',Y.shape)\n",
    "print()\n",
    "print(W)\n",
    "print()\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (5, 10)\n",
      "W: (10, 3)\n",
      "B: (3,)\n",
      "Y: (5, 3)\n",
      "\n",
      "[[-0.66481113 -0.52674556 -0.61355346]\n",
      " [ 0.40042913  0.34762692 -0.35688666]\n",
      " [ 0.411991   -0.39023295 -0.20915076]\n",
      " [ 0.4533671   0.21780533 -0.12565094]\n",
      " [-0.15490568 -0.40375385  0.04237068]\n",
      " [ 0.09114134 -0.31263256 -0.4698606 ]\n",
      " [ 0.04551554 -0.22495773 -0.2946378 ]\n",
      " [-0.17980325  0.3099935   0.11367899]\n",
      " [ 0.19926697  0.6702039   0.3964895 ]\n",
      " [ 0.2754177  -0.214158   -0.65305364]]\n",
      "\n",
      "Y(tensor): tf.Tensor(\n",
      "[[0.427451   0.74169433 0.807637  ]\n",
      " [0.44275445 0.09695899 0.07993889]\n",
      " [0.4634342  0.4604019  0.52215827]\n",
      " [0.51897854 0.7522563  0.81984365]\n",
      " [0.44413015 0.4013339  0.28929877]], shape=(5, 3), dtype=float32)\n",
      "Y(man_matmul): tf.Tensor(\n",
      "[[0.427451   0.74169433 0.807637  ]\n",
      " [0.44275445 0.09695899 0.07993888]\n",
      " [0.46343422 0.46040192 0.5221583 ]\n",
      " [0.51897854 0.75225633 0.8198437 ]\n",
      " [0.44413015 0.40133393 0.2892988 ]], shape=(5, 3), dtype=float32)\n",
      "Y(y_man_vec): [[0.42745101 0.74169434 0.80763698]\n",
      " [0.44275439 0.09695896 0.07993889]\n",
      " [0.4634342  0.46040194 0.5221583 ]\n",
      " [0.51897856 0.7522563  0.81984369]\n",
      " [0.44413014 0.40133391 0.28929882]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.math import exp\n",
    "from tensorflow.linalg import matmul\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "N, n_feature =5, 10\n",
    "X= tf.random.normal(shape=(N,n_feature))\n",
    "\n",
    "n_neuron=3\n",
    "dense=Dense(units=n_neuron, activation='sigmoid')\n",
    "Y=dense(X)\n",
    "\n",
    "W,B = dense.get_weights()\n",
    "\n",
    "print('X:',X.shape)\n",
    "print('W:',W.shape)\n",
    "print('B:',B.shape)\n",
    "print('Y:',Y.shape)\n",
    "print()\n",
    "print(W)\n",
    "print()\n",
    "print('Y(tensor):',Y)\n",
    "\n",
    "# calculate with matrix multiplication\n",
    "z=matmul(X,W)+B\n",
    "y_man_matmul=1/(1+exp(-z))\n",
    "print('Y(man_matmul):',y_man_matmul)\n",
    "\n",
    "# numpy로 (tensor은 역전파때매 슬라이싱 입력 불가하기 때매 numpy로)\n",
    "y_man_vec=np.zeros(shape=(N,n_neuron))\n",
    "for x_idx in range(N):\n",
    "    x=X[x_idx]\n",
    "    for nu_idx in range(n_neuron):\n",
    "        w, b=W[:, nu_idx], B[nu_idx]\n",
    "        # 이게 dot product인가 보네?\n",
    "        z=tf.reduce_sum(x*w)+b\n",
    "        a=1/(1+np.exp(-z))\n",
    "        y_man_vec[x_idx, nu_idx]=a\n",
    "        \n",
    "print('Y(y_man_vec):',y_man_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

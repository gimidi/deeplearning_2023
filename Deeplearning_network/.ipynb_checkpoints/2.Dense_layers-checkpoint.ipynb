{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "딥러닝 architecture\n",
    "corelation filter들을 묶어서 filter bank를 만들고\n",
    "그 filter bank의 Cascaded 구조가 딥러닝 구조임\n",
    "\n",
    "블랙박스가 아니다\n",
    "MFCC가 여기서 나오네.. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "어쨌든 각 레이어마다 다른 주파수의 영역을 판단한다는걸 말하고자했던거 같음\n",
    "'''\n",
    "\"Cascaded Deep Learning\"은 다단계로 연결된 심층 학습 모델을 의미합니다. 이는 여러 개의 신경망이 연속적으로 학습되어 더 복잡한 작업을 수행하는 방식을 나타냅니다.\n",
    "\n",
    "일반적으로, 첫 번째 신경망은 초기 입력 데이터를 받아 중간 수준의 특징을 추출합니다. 이 특징들은 두 번째 신경망에 전달되어 더 높은 수준의 특징을 추출합니다. 이런 식으로 여러 단계를 거쳐 더 복잡한 정보를 추출하게 됩니다.\n",
    "\n",
    "예를 들어, 얼굴 인식 시스템에서는 첫 번째 신경망이 저수준의 특징 (예: 선, 에지)을 추출하고, 두 번째 신경망은 이러한 특징을 결합하여 눈, 코, 입과 같은 고수준의 특징을 추출할 수 있습니다.\n",
    "\n",
    "Cascaded Deep Learning의 장점은 다양한 수준의 특징을 추출하고 이를 활용하여 더 정확한 예측이나 분류를 수행할 수 있다는 점입니다. 또한 각 단계에서 학습된 모델을 재사용하여 효율적으로 학습할 수 있습니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "뉴런마다 인풋값이 전부다 연결되어있는것\n",
    "네트워크\n",
    "node(뉴런)-edge(커넥션)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "선형대수특 값을 따로 가지고다니기 귀찮아서 한꺼번에 vector, matrix 형태로 가지고다님\n",
    "셋팅한 1,2,3...n개의 뉴런의 연산을 그대로 해줄 수 있는 구조로 만든거임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x^TW+b^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias로 row vector로 만드는데, 나중에 broadcasting같은 기능 사용할때 더 편함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "그리고 그냥 뉴런 하나씩 연산하고 activation scalar형태로 태우는거니까\n",
    "뉴런갯수만큼 vector가 layer의 output으로 나오겠지\n",
    "뉴련갯수 왜 헷갈리게 l로 표기하는걸까.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$R^{1 \\times l}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row vector(xT)를 넣어서 row vertor(결국 각각의 activation value들)가 나온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "저번시간이랑 다른게 뭔지 잘 모르겠네"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "그 다음 레이어부터는 xT가 아니라 output자체가 넘어옴. l길이를 가진 row vector\n",
    "새로운 xT로 봐줘도 되겠다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$W \\in {R^{l_{i-1} \\times l_i}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "결국 이전 결과 i-1번째의 뉴런길이 l_{i-1}와 현재 뉴런길이가 W의 크기를 만듦"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
